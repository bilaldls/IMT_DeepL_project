import csv
import math
import time
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
from dateutil import parser as dateparser

from skyfield.api import Loader, EarthSatellite
from astroquery.jplhorizons import Horizons
from astropy.time import Time
from requests.exceptions import HTTPError

# =========================
# 1) Constantes
# =========================

CSV_TLE_FILE = "iss_last_20_tles_spacetrack.csv"  # attention : modifier si besoin avec le chemin du fichier TLE
HORIZONS_ID = "-125544"  # ISS
STEP_MINUTES = 5
EXTRA_HOURS_LAST = 6
OUTPUT_DATASET = "dataset_iss_sgp4_vs_horizons.csv"

HORIZONS_CHUNK_SIZE = 20   # taille fixe pour les requêtes Horizons
MAX_RETRIES = 3          # nb de tentatives par chunk avant NaN
RETRY_SLEEP_SECONDS = 3  # pause entre tentatives

load = Loader(".")
ts = load.timescale()


# =========================
# 2) Chargement des TLE
# =========================

def load_tles_from_csv(path):
    """
    Lit un CSV epoch;name;line1;line2 et renvoie une liste triée :
    [(epoch_dt, name, l1, l2), ...]
    """
    df = pd.read_csv(path, sep=";")
    tles = []
    for _, row in df.iterrows():
        epoch_str = row["epoch"]
        epoch_dt = dateparser.parse(epoch_str)  # gère ISO automatiquement
        name = str(row["name"])
        l1 = str(row["line1"])
        l2 = str(row["line2"])
        tles.append((epoch_dt, name, l1, l2))

    # tri par epoch croissant
    tles.sort(key=lambda x: x[0])
    return tles


# =========================
# 3) Trajectoire SGP4
# =========================

def generate_sgp4_trajectory(tles, step_minutes=STEP_MINUTES,
                             extra_hours_last=EXTRA_HOURS_LAST):
    """
    tles: liste (epoch_dt, name, l1, l2) triée.
    Retourne:
        times_dt      : liste de datetime UTC
        sgp4_pos      : np.ndarray (N,3) positions (km)
        tle_index     : liste d'indices TLE (0,1,2,…) pour chaque point
        dt_since_tle  : np.ndarray (N,) delta t en secondes depuis l'epoch du TLE
    """
    all_times = []
    all_positions = []
    all_tle_idx = []
    all_dt_since = []

    for idx, (epoch_dt, name, l1, l2) in enumerate(tles):
        sat = EarthSatellite(l1, l2, name, ts)

        if idx < len(tles) - 1:
            next_epoch_dt = tles[idx + 1][0]
        else:
            next_epoch_dt = epoch_dt + timedelta(hours=extra_hours_last)

        print(f"TLE #{idx:02d} : propagation de {epoch_dt} à {next_epoch_dt}")

        current_dt = epoch_dt
        while current_dt < next_epoch_dt:
            all_times.append(current_dt)
            all_tle_idx.append(idx)

            dt_sec = (current_dt - epoch_dt).total_seconds()
            all_dt_since.append(dt_sec)

            t_sf = ts.utc(current_dt.year, current_dt.month, current_dt.day,
                          current_dt.hour, current_dt.minute, current_dt.second)
            geo = sat.at(t_sf)
            x, y, z = geo.position.km
            all_positions.append((x, y, z))

            current_dt = current_dt + timedelta(minutes=step_minutes)

    sgp4_pos = np.array(all_positions)
    dt_since_tle = np.array(all_dt_since)
    return all_times, sgp4_pos, all_tle_idx, dt_since_tle


# =========================
# 4) Positions Horizons (robuste : chunks fixes + retries + NaN)
# =========================

def fetch_horizons_positions(times_dt, horizons_id=HORIZONS_ID):
    """
    Récupère les positions Horizons pour une liste de datetime.
    - Convertit en JD TDB (comme attendu par Horizons pour .vectors())
    - Requête en chunks fixes de HORIZONS_CHUNK_SIZE (20 par 20)
      avec retries en cas de HTTPError (ex: 502)
    - Demande un repère équatorial (refplane='earth') pour matcher SGP4.

    Retourne np.ndarray (N,3) en km (avec éventuellement des NaN).
    """
    print(
        f"Requête Horizons pour {len(times_dt)} dates "
        f"(chunks de {HORIZONS_CHUNK_SIZE}, retries)..."
    )

    # 1) Conversion des datetimes UTC -> JD en TDB (échelle de temps Horizons vectors)
    t = Time(times_dt, scale="utc")
    times_jd_tdb = t.tdb.jd

    positions = []  # même ordre que times_jd_tdb

    for start_idx in range(0, len(times_jd_tdb), HORIZONS_CHUNK_SIZE):
        jd_chunk = times_jd_tdb[start_idx:start_idx + HORIZONS_CHUNK_SIZE]
        print(
            f"-> chunk de {len(jd_chunk)} epochs "
            f"(positions {start_idx} à {start_idx + len(jd_chunk) - 1})"
        )

        success = False
        for attempt in range(1, MAX_RETRIES + 1):
            try:
                obj = Horizons(
                    id=horizons_id,
                    location="500@399",      # géocentre terrestre
                    epochs=jd_chunk
                )
                # 2) Référentiel équatorial (compatible ICRS/GCRS)
                vec = obj.vectors(refplane="earth", delta_T=True)

                AU_KM = 149597870.7
                x = np.array(vec["x"]) * AU_KM
                y = np.array(vec["y"]) * AU_KM
                z = np.array(vec["z"]) * AU_KM

                for i in range(len(x)):
                    positions.append([x[i], y[i], z[i]])

                success = True
                break

            except HTTPError as e:
                print(f"  HTTPError tentative {attempt}/{MAX_RETRIES} : {e}")
                if attempt < MAX_RETRIES:
                    print(f"    -> pause {RETRY_SLEEP_SECONDS}s puis retry")
                    time.sleep(RETRY_SLEEP_SECONDS)
                else:
                    print(f"    -> échec après {MAX_RETRIES} tentatives")

        if not success:
            print(f"  !! Échec définitif pour ce chunk -> NaN pour {len(jd_chunk)} epochs")
            for _ in jd_chunk:
                positions.append([np.nan, np.nan, np.nan])

    positions = np.array(positions)
    if positions.shape[0] != len(times_jd_tdb):
        raise RuntimeError(
            f"Incohérence : {positions.shape[0]} positions pour {len(times_jd_tdb)} dates"
        )

    return positions


# =========================
# 5) Construction du dataset
# =========================

def build_dataset():
    # 1) TLE
    tles = load_tles_from_csv(CSV_TLE_FILE)
    print(f"{len(tles)} TLE chargés depuis {CSV_TLE_FILE}")

    # 2) SGP4
    times_dt, sgp4_pos, tle_idx, dt_since_tle = generate_sgp4_trajectory(tles)

    # 3) Horizons
    horizons_pos = fetch_horizons_positions(times_dt)

    if sgp4_pos.shape != horizons_pos.shape:
        raise RuntimeError("Dimensions différentes entre SGP4 et Horizons")

    # 4) Erreurs
    diff = sgp4_pos - horizons_pos
    err_norm = np.linalg.norm(diff, axis=1)

    # 5) Infos TLE associées
    tle_epochs = [tles[i][0] for i in tle_idx]

    # 6) DataFrame final
    df = pd.DataFrame({
        "time_utc": [dt.isoformat() for dt in times_dt],
        "tle_index": tle_idx,
        "tle_epoch": [e.isoformat() for e in tle_epochs],
        "dt_since_tle_s": dt_since_tle,
        "x_sgp4_km": sgp4_pos[:, 0],
        "y_sgp4_km": sgp4_pos[:, 1],
        "z_sgp4_km": sgp4_pos[:, 2],
        "x_horizons_km": horizons_pos[:, 0],
        "y_horizons_km": horizons_pos[:, 1],
        "z_horizons_km": horizons_pos[:, 2],
        "dx_km": diff[:, 0],
        "dy_km": diff[:, 1],
        "dz_km": diff[:, 2],
        "error_norm_km": err_norm,
    })

    df.to_csv(OUTPUT_DATASET, sep=";", index=False)
    print(f"Dataset écrit dans {OUTPUT_DATASET}")
    print(df.head())


if __name__ == "__main__":
    build_dataset()
